{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHL92qJFZrO8",
        "outputId": "0e5e08ea-ce58-43fd-cbff-5ae6124ef2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nt2F1H9TYsqG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blk = lambda ic, oc: nn.Sequential(\n",
        "    nn.Conv2d(ic, oc, 5, padding=2),\n",
        "    nn.GroupNorm(oc // 8, oc),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Conv2d(oc, oc, 5, padding=2),\n",
        "    nn.GroupNorm(oc // 8, oc),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Conv2d(oc, oc, 5, padding=2),\n",
        "    nn.GroupNorm(oc // 8, oc),\n",
        "    nn.LeakyReLU(),\n",
        ")\n",
        "\n",
        "blku = lambda ic, oc: nn.Sequential(\n",
        "    nn.Conv2d(ic, oc, 5, padding=2),\n",
        "    nn.GroupNorm(oc // 8, oc),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Conv2d(oc, oc, 5, padding=2),\n",
        "    nn.GroupNorm(oc // 8, oc),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Conv2d(oc, oc, 5, padding=2),\n",
        "    nn.GroupNorm(oc // 8, oc),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.ConvTranspose2d(oc, oc, 2, stride=2),\n",
        "    nn.GroupNorm(oc // 8, oc),\n",
        "    nn.LeakyReLU(),\n",
        ")\n",
        "\n",
        "\n",
        "class DummyX0Model(nn.Module):\n",
        "\n",
        "    def __init__(self, n_channel: int, N: int = 16) -> None:\n",
        "        super(DummyX0Model, self).__init__()\n",
        "        self.down1 = blk(n_channel, 16)\n",
        "        self.down2 = blk(16, 32)\n",
        "        self.down3 = blk(32, 64)\n",
        "        self.down4 = blk(64, 512)\n",
        "        self.down5 = blk(512, 512)\n",
        "        self.up1 = blku(512, 512)\n",
        "        self.up2 = blku(512 + 512, 64)\n",
        "        self.up3 = blku(64, 32)\n",
        "        self.up4 = blku(32, 16)\n",
        "        self.convlast = blk(16, 16)\n",
        "        self.final = nn.Conv2d(16, N * n_channel, 1, bias=False)\n",
        "\n",
        "        self.tr1 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "        self.tr2 = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "        self.tr3 = nn.TransformerEncoderLayer(d_model=64, nhead=8)\n",
        "\n",
        "        self.cond_embedding_1 = nn.Embedding(10, 16)\n",
        "        self.cond_embedding_2 = nn.Embedding(10, 32)\n",
        "        self.cond_embedding_3 = nn.Embedding(10, 64)\n",
        "        self.cond_embedding_4 = nn.Embedding(10, 512)\n",
        "        self.cond_embedding_5 = nn.Embedding(10, 512)\n",
        "        self.cond_embedding_6 = nn.Embedding(10, 64)\n",
        "\n",
        "        self.temb_1 = nn.Linear(32, 16)\n",
        "        self.temb_2 = nn.Linear(32, 32)\n",
        "        self.temb_3 = nn.Linear(32, 64)\n",
        "        self.temb_4 = nn.Linear(32, 512)\n",
        "        self.N = N\n",
        "\n",
        "    def forward(self, x, t, cond) -> torch.Tensor:\n",
        "        x = (2 * x.float() / self.N) - 1.0\n",
        "        t = t.float().reshape(-1, 1) / 1000\n",
        "        t_features = [torch.sin(t * 3.1415 * 2**i) for i in range(16)] + [\n",
        "            torch.cos(t * 3.1415 * 2**i) for i in range(16)\n",
        "        ]\n",
        "        tx = torch.cat(t_features, dim=1).to(x.device)\n",
        "\n",
        "        t_emb_1 = self.temb_1(tx).unsqueeze(-1).unsqueeze(-1)\n",
        "        t_emb_2 = self.temb_2(tx).unsqueeze(-1).unsqueeze(-1)\n",
        "        t_emb_3 = self.temb_3(tx).unsqueeze(-1).unsqueeze(-1)\n",
        "        t_emb_4 = self.temb_4(tx).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        cond_emb_1 = self.cond_embedding_1(cond).unsqueeze(-1).unsqueeze(-1)\n",
        "        cond_emb_2 = self.cond_embedding_2(cond).unsqueeze(-1).unsqueeze(-1)\n",
        "        cond_emb_3 = self.cond_embedding_3(cond).unsqueeze(-1).unsqueeze(-1)\n",
        "        cond_emb_4 = self.cond_embedding_4(cond).unsqueeze(-1).unsqueeze(-1)\n",
        "        cond_emb_5 = self.cond_embedding_5(cond).unsqueeze(-1).unsqueeze(-1)\n",
        "        cond_emb_6 = self.cond_embedding_6(cond).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        x1 = self.down1(x) + t_emb_1 + cond_emb_1\n",
        "        x2 = self.down2(nn.functional.avg_pool2d(x1, 2)) + t_emb_2 + cond_emb_2\n",
        "        x3 = self.down3(nn.functional.avg_pool2d(x2, 2)) + t_emb_3 + cond_emb_3\n",
        "        x4 = self.down4(nn.functional.avg_pool2d(x3, 2)) + t_emb_4 + cond_emb_4\n",
        "        x5 = self.down5(nn.functional.avg_pool2d(x4, 2))\n",
        "\n",
        "        x5 = (\n",
        "            self.tr1(x5.reshape(x5.shape[0], x5.shape[1], -1).transpose(1, 2))\n",
        "            .transpose(1, 2)\n",
        "            .reshape(x5.shape)\n",
        "        )\n",
        "\n",
        "        y = self.up1(x5) + cond_emb_5\n",
        "\n",
        "        y = (\n",
        "            self.tr2(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2))\n",
        "            .transpose(1, 2)\n",
        "            .reshape(y.shape)\n",
        "        )\n",
        "\n",
        "        y = self.up2(torch.cat([x4, y], dim=1)) + cond_emb_6\n",
        "\n",
        "        y = (\n",
        "            self.tr3(y.reshape(y.shape[0], y.shape[1], -1).transpose(1, 2))\n",
        "            .transpose(1, 2)\n",
        "            .reshape(y.shape)\n",
        "        )\n",
        "        y = self.up3(y)\n",
        "        y = self.up4(y)\n",
        "        y = self.convlast(y)\n",
        "        y = self.final(y)\n",
        "\n",
        "        # reshape to B, C, H, W, N\n",
        "        y = (\n",
        "            y.reshape(y.shape[0], -1, self.N, *x.shape[2:])\n",
        "            .transpose(2, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "JN5gevP1Y38D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class D3PM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        x0_model: nn.Module,\n",
        "        n_T: int,\n",
        "        num_classes: int = 10,\n",
        "        forward_type=\"uniform\",\n",
        "        hybrid_loss_coeff=0.001,\n",
        "    ) -> None:\n",
        "        super(D3PM, self).__init__()\n",
        "        self.x0_model = x0_model\n",
        "\n",
        "        self.n_T = n_T\n",
        "        self.hybrid_loss_coeff = hybrid_loss_coeff\n",
        "\n",
        "        steps = torch.arange(n_T + 1, dtype=torch.float64) / n_T\n",
        "        alpha_bar = torch.cos((steps + 0.008) / 1.008 * torch.pi / 2)\n",
        "        self.beta_t = torch.minimum(\n",
        "            1 - alpha_bar[1:] / alpha_bar[:-1], torch.ones_like(alpha_bar[1:]) * 0.999\n",
        "        )\n",
        "\n",
        "        # self.beta_t = [1 / (self.n_T - t + 1) for t in range(1, self.n_T + 1)]\n",
        "        self.eps = 1e-6\n",
        "        self.num_classses = num_classes\n",
        "        q_onestep_mats = []\n",
        "        q_mats = []  # these are cumulative\n",
        "\n",
        "        for beta in self.beta_t:\n",
        "\n",
        "            if forward_type == \"uniform\":\n",
        "                mat = torch.ones(num_classes, num_classes) * beta / num_classes\n",
        "                mat.diagonal().fill_(1 - (num_classes - 1) * beta / num_classes)\n",
        "                q_onestep_mats.append(mat)\n",
        "            else:\n",
        "                raise NotImplementedError\n",
        "        q_one_step_mats = torch.stack(q_onestep_mats, dim=0)\n",
        "\n",
        "        q_one_step_transposed = q_one_step_mats.transpose(\n",
        "            1, 2\n",
        "        )  # this will be used for q_posterior_logits\n",
        "\n",
        "        q_mat_t = q_onestep_mats[0]\n",
        "        q_mats = [q_mat_t]\n",
        "        for idx in range(1, self.n_T):\n",
        "            q_mat_t = q_mat_t @ q_onestep_mats[idx]\n",
        "            q_mats.append(q_mat_t)\n",
        "        q_mats = torch.stack(q_mats, dim=0)\n",
        "        self.logit_type = \"logit\"\n",
        "\n",
        "        # register\n",
        "        self.register_buffer(\"q_one_step_transposed\", q_one_step_transposed)\n",
        "        self.register_buffer(\"q_mats\", q_mats)\n",
        "\n",
        "        assert self.q_mats.shape == (\n",
        "            self.n_T,\n",
        "            num_classes,\n",
        "            num_classes,\n",
        "        ), self.q_mats.shape\n",
        "\n",
        "    def _at(self, a, t, x):\n",
        "        # t is 1-d, x is integer value of 0 to num_classes - 1\n",
        "        bs = t.shape[0]\n",
        "        t = t.reshape((bs, *[1] * (x.dim() - 1)))\n",
        "        # out[i, j, k, l, m] = a[t[i, j, k, l], x[i, j, k, l], m]\n",
        "        return a[t - 1, x, :]\n",
        "\n",
        "    def q_posterior_logits(self, x_0, x_t, t):\n",
        "        # if t == 1, this means we return the L_0 loss, so directly try to x_0 logits.\n",
        "        # otherwise, we return the L_{t-1} loss.\n",
        "        # Also, we never have t == 0.\n",
        "\n",
        "        # if x_0 is integer, we convert it to one-hot.\n",
        "        if x_0.dtype == torch.int64 or x_0.dtype == torch.int32:\n",
        "            x_0_logits = torch.log(\n",
        "                torch.nn.functional.one_hot(x_0, self.num_classses) + self.eps\n",
        "            )\n",
        "        else:\n",
        "            x_0_logits = x_0.clone()\n",
        "\n",
        "        assert x_0_logits.shape == x_t.shape + (self.num_classses,), print(\n",
        "            f\"x_0_logits.shape: {x_0_logits.shape}, x_t.shape: {x_t.shape}\"\n",
        "        )\n",
        "\n",
        "        # Here, we caclulate equation (3) of the paper. Note that the x_0 Q_t x_t^T is a normalizing constant, so we don't deal with that.\n",
        "\n",
        "        # fact1 is \"guess of x_{t-1}\" from x_t\n",
        "        # fact2 is \"guess of x_{t-1}\" from x_0\n",
        "\n",
        "        fact1 = self._at(self.q_one_step_transposed, t, x_t)\n",
        "\n",
        "        softmaxed = torch.softmax(x_0_logits, dim=-1)  # bs, ..., num_classes\n",
        "        qmats2 = self.q_mats[t - 2].to(dtype=softmaxed.dtype)\n",
        "        # bs, num_classes, num_classes\n",
        "        fact2 = torch.einsum(\"b...c,bcd->b...d\", softmaxed, qmats2)\n",
        "\n",
        "        out = torch.log(fact1 + self.eps) + torch.log(fact2 + self.eps)\n",
        "\n",
        "        t_broadcast = t.reshape((t.shape[0], *[1] * (x_t.dim())))\n",
        "\n",
        "        bc = torch.where(t_broadcast == 1, x_0_logits, out)\n",
        "\n",
        "        return bc\n",
        "\n",
        "    def vb(self, dist1, dist2):\n",
        "\n",
        "        # flatten dist1 and dist2\n",
        "        dist1 = dist1.flatten(start_dim=0, end_dim=-2)\n",
        "        dist2 = dist2.flatten(start_dim=0, end_dim=-2)\n",
        "\n",
        "        out = torch.softmax(dist1 + self.eps, dim=-1) * (\n",
        "            torch.log_softmax(dist1 + self.eps, dim=-1)\n",
        "            - torch.log_softmax(dist2 + self.eps, dim=-1)\n",
        "        )\n",
        "        return out.sum(dim=-1).mean()\n",
        "\n",
        "    def q_sample(self, x_0, t, noise):\n",
        "        # forward process, x_0 is the clean input.\n",
        "        logits = torch.log(self._at(self.q_mats, t, x_0) + self.eps)\n",
        "        noise = torch.clip(noise, self.eps, 1.0)\n",
        "        gumbel_noise = -torch.log(-torch.log(noise))\n",
        "        return torch.argmax(logits + gumbel_noise, dim=-1)\n",
        "\n",
        "    def model_predict(self, x_0, t, cond):\n",
        "        # this part exists because in general, manipulation of logits from model's logit\n",
        "        # so they are in form of x_0's logit might be independent to model choice.\n",
        "        # for example, you can convert 2 * N channel output of model output to logit via get_logits_from_logistic_pars\n",
        "        # they introduce at appendix A.8.\n",
        "\n",
        "        predicted_x0_logits = self.x0_model(x_0, t, cond)\n",
        "\n",
        "        return predicted_x0_logits\n",
        "\n",
        "    def forward(self, x: torch.Tensor, cond: torch.Tensor = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Makes forward diffusion x_t from x_0, and tries to guess x_0 value from x_t using x0_model.\n",
        "        x is one-hot of dim (bs, ...), with int values of 0 to num_classes - 1\n",
        "        \"\"\"\n",
        "        t = torch.randint(1, self.n_T, (x.shape[0],), device=x.device)\n",
        "        x_t = self.q_sample(\n",
        "            x, t, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
        "        )\n",
        "        # x_t is same shape as x\n",
        "        assert x_t.shape == x.shape, print(\n",
        "            f\"x_t.shape: {x_t.shape}, x.shape: {x.shape}\"\n",
        "        )\n",
        "        # we use hybrid loss.\n",
        "\n",
        "        predicted_x0_logits = self.model_predict(x_t, t, cond)\n",
        "\n",
        "        # based on this, we first do vb loss.\n",
        "        true_q_posterior_logits = self.q_posterior_logits(x, x_t, t)\n",
        "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x_t, t)\n",
        "\n",
        "        vb_loss = self.vb(true_q_posterior_logits, pred_q_posterior_logits)\n",
        "\n",
        "        predicted_x0_logits = predicted_x0_logits.flatten(start_dim=0, end_dim=-2)\n",
        "        x = x.flatten(start_dim=0, end_dim=-1)\n",
        "\n",
        "        ce_loss = torch.nn.CrossEntropyLoss()(predicted_x0_logits, x)\n",
        "\n",
        "        return self.hybrid_loss_coeff * vb_loss + ce_loss, {\n",
        "            \"vb_loss\": vb_loss.detach().item(),\n",
        "            \"ce_loss\": ce_loss.detach().item(),\n",
        "        }\n",
        "\n",
        "    def p_sample(self, x, t, cond, noise):\n",
        "\n",
        "        predicted_x0_logits = self.model_predict(x, t, cond)\n",
        "        pred_q_posterior_logits = self.q_posterior_logits(predicted_x0_logits, x, t)\n",
        "\n",
        "        noise = torch.clip(noise, self.eps, 1.0)\n",
        "\n",
        "        not_first_step = (t != 1).float().reshape((x.shape[0], *[1] * (x.dim())))\n",
        "\n",
        "        gumbel_noise = -torch.log(-torch.log(noise))\n",
        "        sample = torch.argmax(\n",
        "            pred_q_posterior_logits + gumbel_noise * not_first_step, dim=-1\n",
        "        )\n",
        "        return sample\n",
        "\n",
        "    def sample(self, x, cond=None):\n",
        "        for t in reversed(range(1, self.n_T)):\n",
        "            t = torch.tensor([t] * x.shape[0], device=x.device)\n",
        "            x = self.p_sample(\n",
        "                x, t, cond, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
        "            )\n",
        "\n",
        "        return x\n",
        "\n",
        "    def sample_with_image_sequence(self, x, cond=None, stride=10):\n",
        "        steps = 0\n",
        "        images = []\n",
        "        for t in reversed(range(1, self.n_T)):\n",
        "            t = torch.tensor([t] * x.shape[0], device=x.device)\n",
        "            x = self.p_sample(\n",
        "                x, t, cond, torch.rand((*x.shape, self.num_classses), device=x.device)\n",
        "            )\n",
        "            steps += 1\n",
        "            if steps % stride == 0:\n",
        "                images.append(x)\n",
        "\n",
        "        # if last step is not divisible by stride, we add the last image.\n",
        "        if steps % stride != 0:\n",
        "            images.append(x)\n",
        "\n",
        "        return images\n"
      ],
      "metadata": {
        "id": "igmaPleLZAVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    N = 2  # number of classes for discretized state per pixel\n",
        "    d3pm = D3PM(DummyX0Model(1, N), 1000, num_classes=N, hybrid_loss_coeff=0.0).cuda()\n",
        "    print(f\"Total Param Count: {sum([p.numel() for p in d3pm.x0_model.parameters()])}\")\n",
        "    dataset = MNIST(\n",
        "        \"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Pad(2),\n",
        "            ]\n",
        "        ),\n",
        "    )\n",
        "    dataloader = DataLoader(dataset, batch_size=256, shuffle=True, num_workers=32)\n",
        "\n",
        "    optim = torch.optim.AdamW(d3pm.x0_model.parameters(), lr=1e-3)\n",
        "    d3pm.train()\n",
        "\n",
        "    n_epoch = 10\n",
        "    device = \"cuda\"\n",
        "\n",
        "    global_step = 0\n",
        "    for i in range(n_epoch):\n",
        "\n",
        "        pbar = tqdm(dataloader)\n",
        "        loss_ema = None\n",
        "        for x, cond in pbar:\n",
        "            optim.zero_grad()\n",
        "            x = x.to(device)\n",
        "            cond = cond.to(device)\n",
        "\n",
        "            # discritize x to N bins\n",
        "            x = (x * (N - 1)).round().long().clamp(0, N - 1)\n",
        "            loss, info = d3pm(x, cond)\n",
        "\n",
        "            loss.backward()\n",
        "            norm = torch.nn.utils.clip_grad_norm_(d3pm.x0_model.parameters(), 0.1)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                param_norm = sum([torch.norm(p) for p in d3pm.x0_model.parameters()])\n",
        "\n",
        "            if loss_ema is None:\n",
        "                loss_ema = loss.item()\n",
        "            else:\n",
        "                loss_ema = 0.99 * loss_ema + 0.01 * loss.item()\n",
        "            pbar.set_description(\n",
        "                f\"loss: {loss_ema:.4f}, norm: {norm:.4f}, param_norm: {param_norm:.4f}, vb_loss: {info['vb_loss']:.4f}, ce_loss: {info['ce_loss']:.4f}\"\n",
        "            )\n",
        "            optim.step()\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % 300 == 1:\n",
        "                d3pm.eval()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    cond = torch.arange(0, 4).cuda() % 10\n",
        "                    init_noise = torch.randint(0, N, (4, 1, 32, 32)).cuda()\n",
        "\n",
        "                    images = d3pm.sample_with_image_sequence(\n",
        "                        init_noise, cond, stride=40\n",
        "                    )\n",
        "                    # image sequences to gif\n",
        "                    gif = []\n",
        "                    for image in images:\n",
        "                        x_as_image = make_grid(image.float() / (N - 1), nrow=2)\n",
        "                        img = x_as_image.permute(1, 2, 0).cpu().numpy()\n",
        "                        img = (img * 255).astype(np.uint8)\n",
        "                        gif.append(Image.fromarray(img))\n",
        "\n",
        "                    gif[0].save(\n",
        "                        f\"/content/drive/MyDrive/ASP_Project/sample_{global_step}.gif\",\n",
        "                        save_all=True,\n",
        "                        append_images=gif[1:],\n",
        "                        duration=100,\n",
        "                        loop=0,\n",
        "                    )\n",
        "\n",
        "                    last_img = gif[-1]\n",
        "                    last_img.save(f\"/content/drive/MyDrive/ASP_Project/sample_{global_step}_last.png\")\n",
        "\n",
        "                d3pm.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "QwBhnnTwZWvX",
        "outputId": "cb9e2c75-9de8-4f97-96e7-6537afa7d927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Param Count: 63278080\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.2310, norm: 0.1520, param_norm: 1192.7874, vb_loss: 0.0002, ce_loss: 0.1748: 100%|██████████| 235/235 [02:37<00:00,  1.49it/s]\n",
            "loss: 0.1696, norm: 0.1268, param_norm: 1195.7561, vb_loss: 0.0002, ce_loss: 0.1807: 100%|██████████| 235/235 [02:37<00:00,  1.49it/s]\n",
            "loss: 0.1686, norm: 0.0979, param_norm: 1196.3792, vb_loss: 0.0002, ce_loss: 0.1601: 100%|██████████| 235/235 [02:37<00:00,  1.49it/s]\n",
            "loss: 0.1679, norm: 0.0969, param_norm: 1196.2336, vb_loss: 0.0010, ce_loss: 0.1738: 100%|██████████| 235/235 [02:34<00:00,  1.52it/s]\n",
            "loss: 0.1683, norm: 0.0456, param_norm: 1195.6559, vb_loss: 0.0010, ce_loss: 0.1642:  95%|█████████▍| 223/235 [01:46<00:05,  2.10it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dc6d39b73a5e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mloss_ema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mloss_ema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_ema\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             pbar.set_description(\n\u001b[1;32m     50\u001b[0m                 \u001b[0;34mf\"loss: {loss_ema:.4f}, norm: {norm:.4f}, param_norm: {param_norm:.4f}, vb_loss: {info['vb_loss']:.4f}, ce_loss: {info['ce_loss']:.4f}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mg_BjnlmaNJC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}